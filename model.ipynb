{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "use_own_data = False\n",
    "\n",
    "if use_own_data:\n",
    "    path = '/home/florian/Desktop/Data/'\n",
    "    example_img = plt.imread(path+'IMG/'+os.listdir(path+'IMG')[0])\n",
    "else:\n",
    "    path = '../data/data/'\n",
    "    example_img = plt.imread(path+'IMG/center_2016_12_01_13_30_48_287.jpg')\n",
    "\n",
    "plt.imshow(example_img)\n",
    "\n",
    "img_shape = example_img.shape\n",
    "print('img_shape =',img_shape)\n",
    "\n",
    "top_crop = 60\n",
    "bottom_crop = 0\n",
    "left_crop = 0\n",
    "right_crop = 0\n",
    "\n",
    "x_val = np.arange(0,example_img.shape[1])\n",
    "plt.plot(x_val, np.ones(len(x_val))*top_crop, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "samples = []\n",
    "_angles = []\n",
    "with open(path+'driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader) # skip headers in first row\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "        _angles.append(float(line[3]))\n",
    "        \n",
    "print('number of images (initial data set): ',len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # display example images and angles:\n",
    "# for i in range(3):\n",
    "#     rand_num = np.random.randint(len(samples))\n",
    "#     rand_sample = samples[rand_num]\n",
    "#     center_img_name = path+'IMG/'+rand_sample[0].split('/')[-1]\n",
    "#     center_img = plt.imread(center_img_name)\n",
    "#     center_angle = float(rand_sample[3])\n",
    "#     print(center_angle)\n",
    "#     plt.title('Center angle: ', center_angle)\n",
    "#     plt.imshow(center_img); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration: Display angle distribution and angle over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "# sns.distplot(angles, kde=False)\n",
    "plt.hist(_angles, 30)\n",
    "plt.title('Initial data: steering angle distribution (absolute)')\n",
    "plt.xlabel('Steering angle')\n",
    "plt.show()\n",
    "\n",
    "# %matplotlib notebook\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.plot(_angles)\n",
    "plt.title('Angle over time')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Angle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader) # skip headers in first row\n",
    "    for line in reader:\n",
    "#         for i in range(2):\n",
    "        samples.append(line)\n",
    "        _angles.append(float(line[3]))\n",
    "##         if abs(float(line[3]))>.1:\n",
    "#         _angle_val = abs(float(line[3]))\n",
    "#         if _angle_val==0:\n",
    "#             samples.append(line)\n",
    "#             _angles.append(float(line[3]))\n",
    "#         if _angle_val!=0:\n",
    "#             # Add identical images multiple times for all angles != 0. The model includes a noise layer, which adds small changes to all images.\n",
    "# #             for i in range(int(np.round(_angle_val*10))):\n",
    "#             for i in range(3)\n",
    "#                 samples.append(line)\n",
    "#                 _angles.append(float(line[3]))\n",
    "                \n",
    "print('number of images (augmented data set): ',len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# fig = plt.figure(figsize=(10,6))\n",
    "# # sns.distplot(angles, kde=False)\n",
    "# plt.hist(_angles, 30)\n",
    "# plt.title('Augmented data: steering angle distribution (absolute)')\n",
    "# plt.xlabel('Steering angle')\n",
    "# plt.show()\n",
    "\n",
    "# # %matplotlib notebook\n",
    "# fig = plt.figure(figsize=(10,6))\n",
    "# plt.plot(_angles)\n",
    "# plt.title('Angle over time')\n",
    "# plt.xlabel('Sample')\n",
    "# plt.ylabel('Angle')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "print('number of training samples: ', len(train_samples))\n",
    "print('number of validation samples: ', len(validation_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from scipy import ndimage # for importing image as RGB\n",
    "\n",
    "angle_offset = .25\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1:\n",
    "        samples = sklearn.utils.shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                \n",
    "                center_img_name = path+'IMG/'+batch_sample[0].split('/')[-1]\n",
    "                center_img = plt.imread(center_img_name)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_img)\n",
    "                angles.append(center_angle)\n",
    "                images.append(np.fliplr(center_img))\n",
    "                angles.append(-center_angle)\n",
    "                \n",
    "                left_img_name = path+'IMG/'+batch_sample[1].split('/')[-1]\n",
    "                left_img = plt.imread(left_img_name)\n",
    "                left_angle = center_angle + angle_offset\n",
    "                images.append(left_img)\n",
    "                angles.append(left_angle)\n",
    "                images.append(np.fliplr(left_img))\n",
    "                angles.append(-left_angle)\n",
    "                \n",
    "                right_img_name = path+'IMG/'+batch_sample[2].split('/')[-1]\n",
    "                right_img = plt.imread(right_img_name)\n",
    "                right_angle = center_angle - angle_offset\n",
    "                images.append(right_img)\n",
    "                angles.append(right_angle)\n",
    "                images.append(np.fliplr(right_img))\n",
    "                angles.append(-right_angle)\n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # augmentation\n",
    "# import numpy as np\n",
    "# image_flipped = np.fliplr(image)\n",
    "# measurement_flipped = -measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use all three images\n",
    "#    with open(csv_file, 'r') as f:\n",
    "#         reader = csv.reader(f)\n",
    "#         for row in reader:\n",
    "#             steering_center = float(row[3])\n",
    "\n",
    "#             # create adjusted steering measurements for the side camera images\n",
    "#             correction = 0.2 # this is a parameter to tune\n",
    "#             steering_left = steering_center + correction\n",
    "#             steering_right = steering_center - correction\n",
    "\n",
    "#             # read in images from center, left and right cameras\n",
    "#             path = \"...\" # fill in the path to your training IMG directory\n",
    "#             img_center = process_image(np.asarray(Image.open(path + row[0])))\n",
    "#             img_left = process_image(np.asarray(Image.open(path + row[1])))\n",
    "#             img_right = process_image(np.asarray(Image.open(path + row[2])))\n",
    "\n",
    "#             # add images and angles to data set\n",
    "#             car_images.extend(img_center, img_left, img_right)\n",
    "#             steering_angles.extend(steering_center, steering_left, steering_right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.is_gpu_available())\n",
    "print(tf.test.gpu_device_name())\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Lambda, Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Cropping2D, GaussianNoise\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import regularizers\n",
    "    \n",
    "# Set batch size\n",
    "batch_size = 32\n",
    "l2_penal = .0 # .0001: overfitting after 8 epochs\n",
    "dr1 = 0.3\n",
    "dr2 = 0.2\n",
    "dr3 = 0.1\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size=batch_size)\n",
    "\n",
    "\n",
    "row, col, ch = img_shape[0], img_shape[1], img_shape[2]  # Trimmed image format\n",
    "\n",
    "model = Sequential()\n",
    "# normalize data \n",
    "model.add(Lambda(lambda x: x/127.5 - 1., input_shape=(row, col, ch), output_shape=(row, col, ch)))\n",
    "# crop images\n",
    "model.add(Cropping2D(cropping=((top_crop, bottom_crop),(left_crop, right_crop))))\n",
    "# add noise layer\n",
    "model.add(GaussianNoise(.1))\n",
    "# add convolutional layers\n",
    "model.add(Conv2D(24, kernel_size=(5, 5), strides=(2,2), activation='relu'))#, subsample=(2, 2)))\n",
    "model.add(Conv2D(36, kernel_size=(5, 5), strides=(2,2), activation='relu'))#, subsample=(2, 2)))\n",
    "model.add(Conv2D(48, kernel_size=(5, 5), strides=(2,2), activation='relu'))#, subsample=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), strides=(1,1), activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), strides=(1,1), activation='relu'))\n",
    "# add flatten layer\n",
    "model.add(Flatten())\n",
    "# add fully connected layers plus dropout\n",
    "model.add(Dense(100, activation='relu', kernel_regularizer=regularizers.l2(l2_penal)))\n",
    "model.add(Dropout(rate=dr1))\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(l2_penal)))\n",
    "model.add(Dropout(rate=dr2))\n",
    "model.add(Dense(10, activation='relu', kernel_regularizer=regularizers.l2(l2_penal)))\n",
    "model.add(Dropout(rate=dr3))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_path = './model.h5'\n",
    "num_epochs = 30\n",
    "\n",
    "# compile method configures learning process\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# model.compile(optimizer=Adam(learning_rate), loss='mse')# metrics=['accuracy']\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=save_path, monitor='val_loss', save_best_only=True)\n",
    "stopper = EarlyStopping(monitor='val_loss', min_delta=0.0003, patience=3)\n",
    "\n",
    "history = model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=np.ceil(len(train_samples)/batch_size), \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=np.ceil(len(validation_samples)/batch_size), \n",
    "                    callbacks=[checkpoint, stopper],\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=1)\n",
    "\n",
    "# model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
